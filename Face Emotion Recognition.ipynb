{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "34b2af3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense,Dropout,Activation,Conv2D,MaxPooling2D,BatchNormalization,Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping,ReduceLROnPlateau,ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "65953d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angry\n",
      "disgust\n",
      "fear\n",
      "happy\n",
      "neutral\n",
      "sad\n",
      "surprise\n",
      "angry\n",
      "disgust\n",
      "fear\n",
      "happy\n",
      "neutral\n",
      "sad\n",
      "surprise\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>images</th>\n",
       "      <th>labels</th>\n",
       "      <th>purpose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[[123], [123], [126], [131], [124], [69], [10...</td>\n",
       "      <td>angry</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[[127], [121], [124], [137], [123], [118], [1...</td>\n",
       "      <td>angry</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[[255], [255], [255], [255], [255], [255], [2...</td>\n",
       "      <td>angry</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[[22], [12], [12], [13], [16], [15], [19], [3...</td>\n",
       "      <td>angry</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[[17], [18], [19], [19], [17], [15], [16], [1...</td>\n",
       "      <td>angry</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              images labels purpose\n",
       "0  [[[123], [123], [126], [131], [124], [69], [10...  angry       V\n",
       "1  [[[127], [121], [124], [137], [123], [118], [1...  angry       V\n",
       "2  [[[255], [255], [255], [255], [255], [255], [2...  angry       V\n",
       "3  [[[22], [12], [12], [13], [16], [15], [19], [3...  angry       V\n",
       "4  [[[17], [18], [19], [19], [17], [15], [16], [1...  angry       V"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define dictionaries for mapping emotions to integers and vice versa\n",
    "int2emotions = {0:'angry',1:'fear',2:'happy',3:'heutral',4:'sad',5:'surprise',6:'disgust'}\n",
    "emotions2int = {'angry':0,'fear':1,'happy':2,'neutral':3,'sad':4,'surprise':5,'disgust':6}\n",
    "\n",
    "# Data structure to hold image paths, labels, and purpose\n",
    "dic = {'images':[], 'labels':[], 'purpose':[]}\n",
    "    \n",
    "# Iterate through the directory structure to gather image data    \n",
    "for d in os.listdir('E://TNSDC//model/'):\n",
    "    for emotion in os.listdir(f'E:/TNSDC/model/{d}'):\n",
    "        print(emotion)\n",
    "        for i in os.listdir(f'E:/TNSDC/model/{d}/{emotion}'):\n",
    "            img = cv2.imread(f'E:/TNSDC/model/{d}/{emotion}/{i}',0)\n",
    "            img = img.reshape(48,48,1)\n",
    "            \n",
    "            dic['images'].append(img)\n",
    "            dic['labels'].append(emotion)\n",
    "            \n",
    "            if d=='train':\n",
    "                dic['purpose'].append('T')\n",
    "            else:\n",
    "                dic['purpose'].append('V')\n",
    "\n",
    "# Convert dictionary to DataFrame\n",
    "df = pd.DataFrame(dic)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3efd91e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and validation sets\n",
    "train_data = df[df['purpose']=='T']\n",
    "val_data = df[df['purpose']=='V']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4cf15e21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>images</th>\n",
       "      <th>labels</th>\n",
       "      <th>purpose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5300</th>\n",
       "      <td>[[[221], [218], [222], [230], [235], [240], [2...</td>\n",
       "      <td>angry</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5301</th>\n",
       "      <td>[[[11], [8], [9], [10], [7], [7], [9], [8], [9...</td>\n",
       "      <td>angry</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5302</th>\n",
       "      <td>[[[146], [138], [148], [155], [160], [162], [1...</td>\n",
       "      <td>angry</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5303</th>\n",
       "      <td>[[[218], [163], [16], [3], [7], [9], [3], [8],...</td>\n",
       "      <td>angry</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5304</th>\n",
       "      <td>[[[8], [7], [9], [11], [9], [8], [11], [14], [...</td>\n",
       "      <td>angry</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 images labels purpose\n",
       "5300  [[[221], [218], [222], [230], [235], [240], [2...  angry       T\n",
       "5301  [[[11], [8], [9], [10], [7], [7], [9], [8], [9...  angry       T\n",
       "5302  [[[146], [138], [148], [155], [160], [162], [1...  angry       T\n",
       "5303  [[[218], [163], [16], [3], [7], [9], [3], [8],...  angry       T\n",
       "5304  [[[8], [7], [9], [11], [9], [8], [11], [14], [...  angry       T"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cd8b4668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>images</th>\n",
       "      <th>labels</th>\n",
       "      <th>purpose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[[123], [123], [126], [131], [124], [69], [10...</td>\n",
       "      <td>angry</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[[127], [121], [124], [137], [123], [118], [1...</td>\n",
       "      <td>angry</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[[255], [255], [255], [255], [255], [255], [2...</td>\n",
       "      <td>angry</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[[22], [12], [12], [13], [16], [15], [19], [3...</td>\n",
       "      <td>angry</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[[17], [18], [19], [19], [17], [15], [16], [1...</td>\n",
       "      <td>angry</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              images labels purpose\n",
       "0  [[[123], [123], [126], [131], [124], [69], [10...  angry       V\n",
       "1  [[[127], [121], [124], [137], [123], [118], [1...  angry       V\n",
       "2  [[[255], [255], [255], [255], [255], [255], [2...  angry       V\n",
       "3  [[[22], [12], [12], [13], [16], [15], [19], [3...  angry       V\n",
       "4  [[[17], [18], [19], [19], [17], [15], [16], [1...  angry       V"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8cb9d699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labels\n",
       "happy       2772\n",
       "surprise    1463\n",
       "neutral     1321\n",
       "fear        1194\n",
       "sad         1128\n",
       "angry       1112\n",
       "disgust      436\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "39c36f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Happy class count: 2772\n",
      "neutral class count: 1321\n",
      "sad class count: 1128\n",
      "fear class count: 1194\n",
      "angry class count: 1112\n",
      "surprise class count: 1463\n",
      "disgust class count: 436\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>images</th>\n",
       "      <th>labels</th>\n",
       "      <th>purpose</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[[191], [174], [157], [157], [162], [162], [1...</td>\n",
       "      <td>sad</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[[172], [175], [169], [177], [178], [176], [1...</td>\n",
       "      <td>happy</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[[192], [190], [194], [192], [193], [202], [8...</td>\n",
       "      <td>happy</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[[5], [6], [7], [18], [25], [27], [28], [21],...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[[37], [39], [34], [58], [113], [124], [135],...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              images   labels purpose\n",
       "0  [[[191], [174], [157], [157], [162], [162], [1...      sad       T\n",
       "1  [[[172], [175], [169], [177], [178], [176], [1...    happy       T\n",
       "2  [[[192], [190], [194], [192], [193], [202], [8...    happy       T\n",
       "3  [[[5], [6], [7], [18], [25], [27], [28], [21],...  neutral       T\n",
       "4  [[[37], [39], [34], [58], [113], [124], [135],...  neutral       T"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "happy_count = (train_data['labels'] == 'happy').sum()\n",
    "print(\"Happy class count:\", happy_count)\n",
    "\n",
    "if happy_count > 0:\n",
    "  happy_df = train_data[train_data['labels'] == 'happy'].sample(n=min(happy_count, 3171))\n",
    "else:\n",
    "  happy_df = pd.DataFrame()\n",
    "neutral_count = (train_data['labels'] == 'neutral').sum()\n",
    "print(\"neutral class count:\", neutral_count)\n",
    "\n",
    "if neutral_count > 0:\n",
    "  neutral_df = train_data[train_data['labels'] == 'neutral'].sample(n=min(neutral_count, 3171))\n",
    "else:\n",
    "  neutral_df = pd.DataFrame()\n",
    "sad_count = (train_data['labels'] == 'sad').sum()\n",
    "print(\"sad class count:\", sad_count)\n",
    "\n",
    "if sad_count > 0:\n",
    "  sad_df = train_data[train_data['labels'] == 'sad'].sample(n=min(sad_count, 3171))\n",
    "else:\n",
    "  sad_df = pd.DataFrame()\n",
    "fear_count = (train_data['labels'] == 'fear').sum()\n",
    "print(\"fear class count:\", fear_count)\n",
    "\n",
    "if fear_count > 0:\n",
    "  fear_df = train_data[train_data['labels'] == 'fear'].sample(n=min(fear_count, 3171))\n",
    "else:\n",
    "  fear_df = pd.DataFrame()\n",
    "angry_count = (train_data['labels'] == 'angry').sum()\n",
    "print(\"angry class count:\", angry_count)\n",
    "\n",
    "if angry_count > 0:\n",
    "  angry_df = train_data[train_data['labels'] == 'angry'].sample(n=min(angry_count, 3171))\n",
    "else:\n",
    "  angry_df = pd.DataFrame()\n",
    "surprise_count = (train_data['labels'] == 'surprise').sum()\n",
    "print(\"surprise class count:\", surprise_count)\n",
    "\n",
    "if surprise_count > 0:\n",
    "  surprise_df = train_data[train_data['labels'] == 'surprise'].sample(n=min(surprise_count, 3171))\n",
    "else:\n",
    "  surprise_df = pd.DataFrame()\n",
    "disgust_count = (train_data['labels'] == 'disgust').sum()\n",
    "print(\"disgust class count:\", disgust_count)\n",
    "\n",
    "if disgust_count > 0:\n",
    "  disgust_df = train_data[train_data['labels'] == 'disgust'].sample(n=min(disgust_count, 3171))\n",
    "else:\n",
    "  disgust_df = pd.DataFrame()\n",
    "\n",
    "train_data = pd.concat([happy_df,neutral_df,sad_df,fear_df,angry_df,surprise_df,disgust_df])\n",
    "\n",
    "train_data = train_data.sample(frac=1)\n",
    "train_data.reset_index(inplace=True)\n",
    "train_data.drop('index',inplace=True,axis=1)\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "babd8fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labels\n",
       "happy       2772\n",
       "surprise    1463\n",
       "neutral     1321\n",
       "fear        1194\n",
       "sad         1128\n",
       "angry       1112\n",
       "disgust      436\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f7b0db3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size= 32\n",
    "classes = 7\n",
    "rows,columns=48,48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "62aadc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to one-hot encoded vectors\n",
    "train_labels = [emotions2int[label] for label in train_data['labels']]\n",
    "train_labels = to_categorical(train_labels)\n",
    "\n",
    "val_labels = [emotions2int[label] for label in val_data['labels']]\n",
    "val_labels = to_categorical(val_labels)\n",
    "\n",
    "\n",
    "train_data = list(train_data['images'])\n",
    "train_data = np.array(train_data)\n",
    "\n",
    "val_data = list(val_data['images'])\n",
    "val_data = np.array(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "00491c85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9426, 48, 48, 1)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a6fa54d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5300, 48, 48, 1)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d43888a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_8 (Conv2D)           (None, 48, 48, 64)        640       \n",
      "                                                                 \n",
      " batch_normalization_11 (Ba  (None, 48, 48, 64)        256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 48, 48, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_12 (Ba  (None, 48, 48, 64)        256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 24, 24, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 24, 24, 64)        0         \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 24, 24, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_13 (Ba  (None, 24, 24, 128)       512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 24, 24, 128)       147584    \n",
      "                                                                 \n",
      " batch_normalization_14 (Ba  (None, 24, 24, 128)       512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPoolin  (None, 12, 12, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 12, 12, 128)       0         \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 12, 12, 256)       295168    \n",
      "                                                                 \n",
      " batch_normalization_15 (Ba  (None, 12, 12, 256)       1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 12, 12, 256)       590080    \n",
      "                                                                 \n",
      " batch_normalization_16 (Ba  (None, 12, 12, 256)       1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPoolin  (None, 6, 6, 256)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 6, 6, 256)         0         \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 6, 6, 512)         1180160   \n",
      "                                                                 \n",
      " batch_normalization_17 (Ba  (None, 6, 6, 512)         2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 6, 6, 512)         2359808   \n",
      "                                                                 \n",
      " batch_normalization_18 (Ba  (None, 6, 6, 512)         2048      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPoolin  (None, 3, 3, 512)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 3, 3, 512)         0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 4608)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 256)               1179904   \n",
      "                                                                 \n",
      " batch_normalization_19 (Ba  (None, 256)               1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_20 (Ba  (None, 128)               512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_21 (Ba  (None, 64)                256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 7)                 455       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5915207 (22.56 MB)\n",
      "Trainable params: 5910471 (22.55 MB)\n",
      "Non-trainable params: 4736 (18.50 KB)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Define the CNN architecture\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "model.add(Conv2D(64,(3,3),activation='elu',input_shape=(rows,columns,1),kernel_initializer='he_normal',padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64,(3,3),activation='elu',input_shape=(rows,columns,1),kernel_initializer='he_normal',padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "model.add(Conv2D(128,(3,3),activation='elu',kernel_initializer='he_normal',padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128,(3,3),activation='elu',kernel_initializer='he_normal',padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "model.add(Conv2D(256,(3,3),activation='elu',kernel_initializer='he_normal',padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(256,(3,3),activation='elu',kernel_initializer='he_normal',padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "model.add(Conv2D(512,(3,3),activation='elu',kernel_initializer='he_normal',padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(512,(3,3),activation='elu',kernel_initializer='he_normal',padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256,activation='elu',kernel_initializer='he_normal'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "model.add(Dense(128,activation='elu',kernel_initializer='he_normal'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "model.add(Dense(64,activation='elu',kernel_initializer='he_normal'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "model.add(Dense(classes,activation='softmax',kernel_initializer='he_normal'))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fb47b776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/11\n",
      "441/441 [==============================] - ETA: 0s - loss: 1.6570 - accuracy: 0.3922\n",
      "Epoch 1: val_loss improved from inf to 1.51394, saving model to model\\6_class_emotion_detector_V2.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "441/441 [==============================] - 774s 2s/step - loss: 1.6570 - accuracy: 0.3922 - val_loss: 1.5139 - val_accuracy: 0.4400\n",
      "Epoch 2/11\n",
      "441/441 [==============================] - ETA: 0s - loss: 1.4983 - accuracy: 0.4402\n",
      "Epoch 2: val_loss improved from 1.51394 to 1.43005, saving model to model\\6_class_emotion_detector_V2.h5\n",
      "441/441 [==============================] - 856s 2s/step - loss: 1.4983 - accuracy: 0.4402 - val_loss: 1.4300 - val_accuracy: 0.4704\n",
      "Epoch 3/11\n",
      "441/441 [==============================] - ETA: 0s - loss: 1.4164 - accuracy: 0.4756\n",
      "Epoch 3: val_loss improved from 1.43005 to 1.38698, saving model to model\\6_class_emotion_detector_V2.h5\n",
      "441/441 [==============================] - 904s 2s/step - loss: 1.4164 - accuracy: 0.4756 - val_loss: 1.3870 - val_accuracy: 0.4785\n",
      "Epoch 4/11\n",
      "441/441 [==============================] - ETA: 0s - loss: 1.3398 - accuracy: 0.5025\n",
      "Epoch 4: val_loss improved from 1.38698 to 1.29662, saving model to model\\6_class_emotion_detector_V2.h5\n",
      "441/441 [==============================] - 789s 2s/step - loss: 1.3398 - accuracy: 0.5025 - val_loss: 1.2966 - val_accuracy: 0.4960\n",
      "Epoch 5/11\n",
      "441/441 [==============================] - ETA: 0s - loss: 1.2725 - accuracy: 0.5268\n",
      "Epoch 5: val_loss did not improve from 1.29662\n",
      "441/441 [==============================] - 772s 2s/step - loss: 1.2725 - accuracy: 0.5268 - val_loss: 1.3450 - val_accuracy: 0.4955\n",
      "Epoch 6/11\n",
      "441/441 [==============================] - ETA: 0s - loss: 1.2131 - accuracy: 0.5528\n",
      "Epoch 6: val_loss improved from 1.29662 to 1.24041, saving model to model\\6_class_emotion_detector_V2.h5\n",
      "441/441 [==============================] - 645s 1s/step - loss: 1.2131 - accuracy: 0.5528 - val_loss: 1.2404 - val_accuracy: 0.5323\n",
      "Epoch 7/11\n",
      "441/441 [==============================] - ETA: 0s - loss: 1.1497 - accuracy: 0.5706\n",
      "Epoch 7: val_loss did not improve from 1.24041\n",
      "441/441 [==============================] - 627s 1s/step - loss: 1.1497 - accuracy: 0.5706 - val_loss: 1.2732 - val_accuracy: 0.5362\n",
      "Epoch 8/11\n",
      "441/441 [==============================] - ETA: 0s - loss: 1.1046 - accuracy: 0.5939\n",
      "Epoch 8: val_loss did not improve from 1.24041\n",
      "441/441 [==============================] - 606s 1s/step - loss: 1.1046 - accuracy: 0.5939 - val_loss: 1.2455 - val_accuracy: 0.5260\n",
      "Epoch 9/11\n",
      "441/441 [==============================] - ETA: 0s - loss: 1.0427 - accuracy: 0.6118\n",
      "Epoch 9: val_loss improved from 1.24041 to 1.21652, saving model to model\\6_class_emotion_detector_V2.h5\n",
      "441/441 [==============================] - 566s 1s/step - loss: 1.0427 - accuracy: 0.6118 - val_loss: 1.2165 - val_accuracy: 0.5451\n",
      "Epoch 10/11\n",
      "441/441 [==============================] - ETA: 0s - loss: 0.9657 - accuracy: 0.6501\n",
      "Epoch 10: val_loss did not improve from 1.21652\n",
      "441/441 [==============================] - 557s 1s/step - loss: 0.9657 - accuracy: 0.6501 - val_loss: 1.3150 - val_accuracy: 0.5362\n",
      "Epoch 11/11\n",
      "309/441 [====================>.........] - ETA: 2:28 - loss: 0.9460 - accuracy: 0.6537WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 4851 batches). You may need to use the repeat() function when building your dataset.\n",
      "\n",
      "Epoch 11: val_loss did not improve from 1.21652\n",
      "441/441 [==============================] - 408s 924ms/step - loss: 0.9460 - accuracy: 0.6537 - val_loss: 1.2576 - val_accuracy: 0.5311\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define callbacks\n",
    "checkpoint = ModelCheckpoint('model\\\\6_class_emotion_detector_V2.h5',\n",
    "                             save_best_only=True,\n",
    "                             mode='min',\n",
    "                             monitor='val_loss',\n",
    "                             verbose=1,\n",
    "                             options=None)\n",
    "\n",
    "earlystopping = EarlyStopping(patience=10,\n",
    "                             verbose=1,\n",
    "                             min_delta=0,\n",
    "                             monitor='val_loss',\n",
    "                             restore_best_weights=True)\n",
    "\n",
    "\n",
    "callbacks = [checkpoint, earlystopping]\n",
    "\n",
    "# Compile the model\n",
    "model.compile(metrics=['accuracy'],\n",
    "             optimizer='rmsprop',\n",
    "             loss='categorical_crossentropy')\n",
    "\n",
    "train_samples = 28273\n",
    "validation_samples = 3534\n",
    "batch_size = 64\n",
    "epochs=11\n",
    "\n",
    "history = model.fit(train_data,\n",
    "                    train_labels,\n",
    "                    epochs=epochs,\n",
    "                    steps_per_epoch=train_samples//batch_size,\n",
    "                    validation_data=(val_data,val_labels),\n",
    "                    validation_steps=validation_samples//batch_size,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "012b69df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 453ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n"
     ]
    }
   ],
   "source": [
    "# Detection of emotions \n",
    "\n",
    "int2emotions = {0: 'Angry', 1: 'Fear', 2: 'Happy', 3: 'Neutral', 4: 'Sad', 5: 'Surprise', 6: 'Disgust'}\n",
    "emotion_text_colors = {'Angry': (0, 0, 255), 'Fear': (0, 128, 255), 'Happy': (0, 255, 0),\n",
    "                       'Neutral': (255, 255, 0), 'Sad': (255, 0, 0), 'Surprise': (255, 165, 0),\n",
    "                       'Disgust': (128, 0, 128)}\n",
    "emotion_bg_colors = {'Angry': (255, 255, 255), 'Fear': (255, 255, 255), 'Happy': (255, 255, 255),\n",
    "                     'Neutral': (255, 255, 255), 'Sad': (255, 255, 255), 'Surprise': (255, 255, 255),\n",
    "                     'Disgust': (255, 255, 255)}\n",
    "\n",
    "model = load_model('model/6_class_emotion_detector_V2.h5') \n",
    "\n",
    "classifier = cv2.CascadeClassifier(r\"E:/TNSDC/haarcascade_frontalface_default.xml\")\n",
    "\n",
    "def add_transparent_text_bg(img, text, pos, font=cv2.FONT_HERSHEY_SIMPLEX, font_scale=1, font_thickness=2, text_color=(0, 0, 0), bg_color=(255, 255, 255), bg_alpha=0.5):\n",
    "    text_size, _ = cv2.getTextSize(text, font, font_scale, font_thickness)\n",
    "    text_x, text_y = pos\n",
    "    overlay = img[text_y:text_y + text_size[1] + 2, text_x:text_x + text_size[0] + 2]\n",
    "    cv2.putText(img, text, pos, font, font_scale, text_color, font_thickness)\n",
    "\n",
    "def detect_face(frame):\n",
    "    if classifier.empty():\n",
    "        print(\"Error: Could not load face cascade classifier.\")\n",
    "        return frame\n",
    "\n",
    "    faces = classifier.detectMultiScale(frame, scaleFactor=1.3, minNeighbors=4)\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 255, 255), 2) \n",
    "\n",
    "        face_roi = frame[y:y+h, x:x+w]\n",
    "        face_roi = cv2.cvtColor(face_roi, cv2.COLOR_BGR2GRAY)  \n",
    "        face_roi = cv2.resize(face_roi, (48, 48)) \n",
    "        face_roi = face_roi.astype('float32') / 255.0 \n",
    "        face_roi = np.expand_dims(face_roi, axis=0) \n",
    "\n",
    "        predicted_emotion = int2emotions[np.argmax(model.predict(face_roi))]\n",
    "        text_color = emotion_text_colors[predicted_emotion]\n",
    "        bg_color = emotion_bg_colors[predicted_emotion]\n",
    "\n",
    "        add_transparent_text_bg(frame, predicted_emotion, (x, y - 30), text_color=text_color, bg_color=bg_color)\n",
    "\n",
    "    return frame\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "cv2.namedWindow('Emotion Detector', cv2.WND_PROP_FULLSCREEN)\n",
    "cv2.setWindowProperty('Emotion Detector', cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        frame = detect_face(frame)\n",
    "        cv2.imshow('Emotion Detector', frame)\n",
    "        if cv2.waitKey(1) == 27:\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
